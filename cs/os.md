# 操作系统概述
什么是操作系统
- 控制应用程序执行的程序
- 应用程序和计算机硬件间的接口

操作系统的目标

- 方便：使计算机更易于使用
- 有效：允许以更有效的方式使用计算机系统资源
- 扩展能力：在不妨碍服务的前提下，有效地开发、测试和引入新的系统功能

操作系统提供的服务

- 程序开发：如编辑器和调试器
- 程序运行：如加载到内存、初始化I/O设备等
- I/O设备访问：隐藏具体的I/O操作指令
- 文件访问控制：屏蔽存储介质细节
- 系统访问：提供接口，防止未授权访问行为
- 错误检测和响应：软、硬件错误
- 记账：收集资源的利用率信息、监控性能特性

## 系统调用
- 操作系统为应用程序提供的与内核进行交互的一组接口
- 应用程序获取操作系统服务的唯一途径
- 系统调用的特殊性在于规定了应用程序进入内核具体位置，即用户访问内核的路径是事先规定好的。

## 操作系统发展进程
串行处理->简单批处理系统->多道批处理系统->分时系统->实时系统
### 串行处理:
处理机制:
- 无操作系统
- 程序员通过操控控制台运行程序，控制台包括显示灯、触发器、某种类型的输入设备和打印机
- 程序通过输入设备（如卡片机阅读器）载入计算机
- 用户按顺序访问计算机

问题:
- 调度：使用硬拷贝登记来预订机器时间
- 准备时间：加载编译器、源程序，保存目标程序，加载目标程序，链接公用函数等。

### 简单批处理系统:
- 对一批作业按顺序进行自动处理
- 内存中只能存放一道作业
- 作业的自动续接
- 内存保护：保护监控程序所在的内存区域
- 定时器：防止某作业独占系统
- 特权指令：只能由监控程序执行的指令
- 中断：早期计算机模型无此能力

### 多道批处理系统(多道性、调度性、无序性、无交互能力):
- 多道程序设计技术可以显著提高系统设备利用率
- 内存中同时存放多个作业
- 多个作业可并发执行
- 作业调度程序负责作业的调度

### 分时系统(多路性、独立性、及时性、交互性):

分时技术就是把处理器的运行时间分成很短的时间片，按时间片轮流把处理器分配给各联机作业使用。若某个作业在分配给它的时间片内不能完成其计算，则该作业暂时停止运行，把处理器让给其他作业使用，等待下一轮再继续运行。由于计算机速度很快，作业运行轮转得很快，给每个用户的感觉好像是自己独占一台计算机。

- 采用多道程序设计技术处理多个交互作业
- 多个用户共享处理器
- 多个用户通过不同终端同时访问系统

|                | 批处理系统多道程序设计          | 分时           |
| -------------- | ------------------------------- | -------------- |
| 主要目标       | 充分利用处理器                  | 减小响应时间   |
| 操作系统指令源 | 作业控制语言命令 作业提供的命令 | 终端键入的命令 |


### 实时系统(可确定性、可响应性、用户控制、可靠性、故障弱化能力):

系统能够及时（即时）响应外部事件的请求，在规定的时间内完成对该事件的处理，并控制所有实时任务协调一致地运行。
# 并发与进程
## 进程
### 进程概念
- 一个正在执行的程序
- 计算机中正在运行的程序的一个实例
- 可分配给处理器并由处理器执行的一个实体
- 由下述表征的活动单元
- 一个单一顺序线程
- 一个当前状态
- 一组相关系统资源

### 进程的组成
- 一段可执行的程序
- 程序所需要的相关数据（变量、工作空间、缓冲区等）
- 程序的执行上下文（execution context）
- 进程状态（process state）
- 操作系统用来管理和控制进程所需的所有数据

## 内存管理
### 存储管理的任务
- 进程隔离：每个进程拥有独立的地址空间，互不干扰
- 自动分配和管理：动态分配，对程序员透明
- 支持模块化程序设计：能够动态加载、销毁程序员定义的模块
- 保护和访问控制：一个应用程序不能任意访问其它程序的存储空间
- 长期存储：关机后仍能长时间存储信息

存储管理的实现方式: 文件系统 + 虚拟存储

文件系统
- 实现了长期存储
- 文件
  - 一个有名称的对象
  - 访问控制和保护的基本单元

虚拟存储
- 程序以逻辑方式访问存储器
- 多作业同时驻留内存
- 每个作业部分驻留
- 换入、换出机制

## 操作系统的4类典型安全问题
- 可用性
  保护系统不被中断
- 机密性
  保证用户不能读取未授权访问的数据
- 完整性
  保护数据不被未授权修改
- 认证
  涉及用户身份的正确认证和消息或数据的合法性


- 并发与并行

> 你吃饭吃到一半，电话来了，你一直到吃完了以后才去接，这就说明你不支持并发也不支持并行。
> 
> 你吃饭吃到一半，电话来了，你停了下来接了电话，接完后继续吃饭，这说明你支持并发。
> 
> 你吃饭吃到一半，电话来了，你一边打电话一边吃饭，这说明你支持并行。
> 
> 并发的关键是你有处理多个任务的能力，不一定要同时。
> 
> 并行的关键是你有同时处理多个任务的能力。
> 
> https://www.zhihu.com/question/33515481

## 操作系统的体系结构

无结构 -> 模块化结构 -> 分层式结构 -> 微内核结构

### 微内核
实现思想: 在操作系统内核中只留下一些最基本的功能，而将其它服务尽可能地从内核中分离出去，用若干个运行在用户态的服务器进程来实现，形成“客户/服务器模式”。普通用户进程通过内核向服务器进程发送请求。

机制与策略
- 机制：实现某一功能的具体执行机构——怎么做
- 策略：方法或原则，用以优化功能实现——做什么

机制与策略的分离

如基于优先级的进程调度中，选择进程，为之分配处理机，使之运行属于机制部分；而为每个进程设定优先级则属于策略部分。

微内核的基本功能

- 进程管理
- 低级存储器管理
- 中断和陷入处理

优点
- 提高了系统的可扩展性
- 增强了系统的可靠性
- 可移植性好
- 提供了对分布式系统的支持


缺点
- 运行效率有所降低：
- 消息传递开销+模式切换开销

## 现代操作系统的特征
- 微内核体系结构
- 分布式操作系统
- 多线程
- 面向对象设计
- 对称多处理

    - 性能高
    - 可用性强
    - 可以增量增长
    - 可扩展性


# 进程与控制
## 进程概览
### 概念

> 来自维基百科

> 进程（英语：process），是指计算机中已运行的程序。进程为曾经是分时系统的基本运作单位。在面向进程设计的系统（如早期的UNIX，Linux 2.4及更早的版本）中，进程是程序的基本执行实体；在面向线程设计的系统（如当代多数操作系统、Linux 2.6及更新的版本）中，进程本身不是基本运行单位，而是线程的容器。程序本身只是指令、数据及其组织形式的描述，进程才是程序（那些指令和数据）的真正运行实例。若干进程有可能与同一个程序相关系，且每个进程皆可以同步（循序）或异步（平行）的方式独立运行。现代计算机系统可在同一段时间内以进程的形式将多个程序加载到存储器中，并借由时间共享（或称时分复用），以在一个处理器上表现出同时（平行性）运行的感觉。同样的，使用多线程技术（多线程即每一个线程都代表一个进程内的一个独立执行上下文）的操作系统或计算机体系结构，同样程序的平行线程，可在多CPU主机或网络上真正同时运行（在不同的CPU上）。

> 操作系统(精髓与设计原理) 中的定义

> - 一个正在执行的程序
> - 一个正在计算机上执行的程序实例
> - 能分配给处理器并由处理器执行的实体
> - 由一组执行的指令, 一个当前状态和一组相关的系统资源表征的活动单元

系统中同时存在的诸进程相互独立，也相互关联。例如，当进程创建另一进程后，父子进程就以某种形式继续保持关联。
如UNIX中，初始化进程是其他所有进程的始祖，与其子女后裔构成一个进程组。
Windows中，没有进程层次的概念，进程地位相等。



进程执行的任意时刻,都可由如下元素来表征:
- 标识符
- 状态
- 优先级
- 程序计数器
- 内存指针
- 上下文数据
- I/O 状态信息
- 记账信息

这些信息放在 PCB(process control block) 中, PCB 由操作系统创建和管理.

用户下达运行程序的命令后，就会产生进程。同一程序可产生多个进程（一对多关系），以允许同时有多位用户运行同一程序，却不会相冲突。

进程需要一些资源才能完成工作，如CPU使用时间、存储器、文件以及I/O设备，且为依序逐一进行，也就是每个CPU核心任何时间内仅能运行一项进程。

进程与线程的区别：进程是计算机管理运行程序的一种方式，一个进程下可包含一个或者多个线程。线程可以理解为子进程。

### 内容
一个计算机系统进程包括（或者说“拥有”）下列数据：

- 那个程序的可执行机器代码的一个在存储器的映像。
- 分配到的存储器（通常是虚拟的一个存储器区域）。存储器的内容包括可执行代码、特定于进程的数据（输入、输出）、调用堆栈、堆栈（用于保存运行时运输中途产生的数据）。
- 分配给该进程的资源的操作系统描述符，诸如文件描述符（Unix术语）或文件句柄（Windows）、数据源和数据终端。
- 安全特性，诸如进程拥有者和进程的权限集（可以容许的操作）。
- 处理器状态（内文），诸如寄存器内容、物理存储器定址等。当进程正在运行时，状态通常存储在寄存器，其他情况在存储器。


### 状态
进程在运行时，状态（state）会改变。所谓状态，就是指进程当前的动作：

- 新生（new）：进程新产生中。
- 运行（running）：正在运行。
- 等待（waiting）：等待某事发生，例如等待用户输入完成。亦称“阻塞”（blocked）
- 就绪（ready）：排班中，等待CPU。
- 结束（terminated）：完成运行。


各状态名称可能随不同操作系统而相异；对于单CPU系统（UP），任何时间可能有多个进程为等待、就绪，但必定仅有一个进程在运行。

![](https://raw.githubusercontent.com/zgw0/blog/master/imgs/processTransformation.png)

多个进程竞争内存资源时可能导致下列现象
- 内存资源紧张, 如何在有限的内存中装入尽量多的进程？
- 无就绪进程，处理机空闲, I/O操作速度远低于CPU计算速度，导致所有进程阻塞，该如何处理？

对换技术（Swapping）

内存中没有就绪进程或内存空间非常紧张时，系统将一个或多个进程的全部或部分程序和数据从内存中换出到磁盘，以腾出部分内存空间。
进程被交换到外存，状态可能变为挂起状态

挂起状态

使执行的进程暂停执行，静止下来，不再参与CPU的竞争，我们把这种静止状态称为挂起状态。

进程挂起的原因
- 进程全部阻塞，处理机空闲
- 系统负荷过重，内存空间紧张
操作系统的需要，操作系统可能需要挂起后台进程或一些服务进程，或某些可能导- 致系统故障的进程。
- 终端用户的请求
- 父进程请求

被挂起进程的特征
- 不能立即执行
- 挂起条件独立于阻塞条件
- 使之挂起的进程：自身、OS、父进程
- 激活挂起进程的进程：实施挂起操作的进程

阻塞与挂起
- 阻塞与否：进程是否等待事件
- 挂起与否：进程是否被换出内存


四种状态组合
- 就绪：进程在内存，准备执行
- 阻塞：进程在内存，等待事件
- 就绪/挂起：进程在外存，只要调入内存并获得CPU即可执行
- 阻塞/挂起：进程在外存，等待事件


![](https://raw.githubusercontent.com/zgw0/blog/master/imgs/processTransformation2.png)

## 内核功能和执行模式
内核（操作系统的核心）
- 操作系统中包含重要系统功能的部分。
- 常驻内存，便于提高操作系统运行效能。

### 功能

不同操作系统对内核的功能范围的设定不同。通常而言，操作系统内核的功能包括

**资源管理功能**
- 进程管理
  - 进程创建和终止
  - 进程的调度和分派
  - 进程切换
  - 进程同步和进程间通信的支持
  - 管理进程控制块 

- 存储管理
  - 为进程分配地址空间
  - 交换
  - 页和段管理

- I/O设备管理
  - I/O缓冲区的管理
  - 为进程分配I/O通道和设备等

**支撑功能**
- 中断处理

  中断处理既是内核的基本功能，也是整个操作系统赖以活动的基础，操作系统的一切重要活动最终都依赖于中断。
- 时钟管理
        
  操作系统的很多功能都依赖于时钟，如时间片控制等。
- 记账（统计、监测）功能

### 执行模式

#### 模式
- 大多数处理器至少支持两种模式：


与操作系统相关的处理器模式——内核模式（系统模式/控制模式）
与用户程序相关的处理器执行模式——用户模式


- 某些指令只能在特权模式下运行


- 读取和修改程序状态字之类的控制寄存器的指令
- 原始I/O指令
- 与内存管理相关的指令
- 部分内存只能在特权模式下访问

#### 采用两种模式的原因

保护操作系统和重要的操作系统表（如PCB）不受程序干扰

#### 处理机如何知道它在什么模式下执行?
程序状态字PSR寄存器中存在指示执行模式的位：

- 当用户调用操作系统服务或中断促发系统例程时，相关位被置为内核模式
- 当从系统服务返回用户进程时，执行模式置为用户模式

#### 模式切换：系统模式和用户模式之间的相互转换
模式切换的原因(用户 -> 系统)
- 系统调用或中断

出现中断时，系统会作如下工作：
- 将程序计数器置为中断处理程序的开始地址
- 从用户模式切换到内核模式，以便中断处理能执行特权指令

模式切换不一定导致进程切换

## 进程控制
- 进程创建与撤销
- 进程阻塞与唤醒
- 挂起与激活
- 进程切换

进程控制由原语来实现, 原语(Primitive):用于完成一定功能的过程。它是原子操作，执行过程中不允许被中断。

### 进程创建与撤销
#### 引起进程创建的典型事件
1. 用户登录, 为终端用户建立一个进程
2. 作业调度(不是进程调度), 为被调度的作业创建进程
3. 提供服务, 如创建打印任务
4. 应用请求, 由应用程序建立多个进程

#### 创建进程的步骤
1. 给新进程分配一个唯一的标识符
2. 为进程分配空间
3. 初始化 PCB
   - 初始化标识信息
   - 初始化处理机状态信息, 如使程序计数器指向程序的入口地址，使栈指针指向栈顶等
   - 初始化进程调度信息, 如设置进程的状态、优先级。

4. 建立连接, 将之插入到就绪或就绪/挂起链表
5. 建立或扩充其他数据结构

#### 进程终止过程
- 根据被终止进程的标识符找到其PCB，读出该进程的状态。
- 若该进程为执行状态，则终止其执行，调度下一个就绪进程执行。
- 若该进程还有子孙进程，还应将其所有子孙进程予以终止，以防他们成为不可控的进程（与具体操作系统的实现密切相关）
- 将该进程所拥有的全部资源，或者归还给其父进程，或者归还给系统。
- 将被终止进程（它的PCB）从所在队列（或链表）中移出，等待其他程序来搜集信息

引起进程终止的事件

- 正常结束：如exit，halt，logoff
- 异常结束：

    - 越界错误
    - 保护错
    - 非法指令
    - 特权指令错
    - 运行超时
    - 等待超时
    - 算术运算错、被0除
    - I/O故障

- 外界干预：

    - 系统员kill进程
    - 父进程终止
    - 父进程请求

### 进程的阻塞与唤醒
#### 引起进程阻塞的事件
- 请求系统服务而得不到满足时，如向系统请求打印，磁盘读数据。
- 启动某种操作而需互斥时：例如进程访问临界区，而临界区暂时被锁定
- 启动某种操作而需同步时：如进程A写，进程B读，则A未写完,B不能读。
- 无新工作可做。

进程阻塞过程
- 正在执行的进程，当发现上述某事件时，由于无法继续执行，于是进程便通过调用阻塞原语block()把自己阻塞。
- 把进程控制块中的现行状态由“执行”改为阻塞，并将PCB插入阻塞队列。
- 调度程序将处理机分配给另一就绪进程，并进行切换。

进程唤醒过程
- 当被阻塞进程所期待的事件出现时，则由有关进程（比如，用完并释放了该I/O设备的进程）调用唤醒原语wakeup()，将等待该事件的进程唤醒。
- 将其PCB中的现行状态由阻塞改为就绪，插入到就绪队列中。

### 进程的挂起与激活
#### 挂起
当出现了引起进程挂起的事件时，系统将利用挂起原语suspend( )将指定进程挂起。

挂起原语的执行过程
- 检查被挂起进程的状态，状态改变：就绪 —> 就绪/挂起；阻塞 —> 阻塞/挂起。
- 插入相应的队列


#### 激活
当发生激活进程的事件时，则可将在外存上处于就绪/挂起状态的进程换入内存。

激活原语的执行过程
- 利用激活原语active()将指定进程从外存调入内存；检查该进程的状态，状态改变：就绪/挂起 —> 就绪；阻塞/挂起 —> 阻塞；
- 插入相应队列。

### 进程的切换
#### 何时会发生进程切换
- 时钟中断：当前执行的进程执行时间超过时间片大小
- I/O中断：操作系统将等待I/O事件的进程改为就绪态，并决定是继续执行当前进程，还是让更高优先级的进程抢占CPU;
- 内存失效：当前进程访问的数据或代码不在内存（引用一个不在内存的字的虚地址）时，当前进程阻塞；
- 陷阱：当前指令的执行出现错误或异常
- 系统调用：处理器移到操作系统内核例程上执行，用户进程阻塞，如file open

#### 进程切换步骤 
- 保存处理器上下文环境，包括程序计数器和其它寄存器
- 更新当前处于运行状态进程的进程控制块
- 将进程的进程控制块移至相应队列（就绪、阻塞等）
- 选择另一进程执行
- 更新其进程控制块信息
- 恢复被选择进程的上下文环境

### UNIX进程控制
- fork()： 创建一个新进程
- exec()： 执行一个可执行程序
- exit()： 终止
- sleep()：暂停一段时间
- pause()：暂停并等待信号
- wait()：等待子进程暂停或终止
- kill()： 发送信号到某个或一组进程
- ptrace() ：设置执行断点(breakpoint)，允许父进程控制子进程的运行

## 线程
**进程回顾**

进程的两个特点

- 资源所有权：一个进程包括一个保存进程映像的虚地址空间，拥有对资源的控制或所有权。
- 调度／执行的基本单位：一个具有状态和优先级，可被被操作系统调度并分派的实体。 

线程的诞生

为区分这两个特点，调度并分派的部分通常称为线程或轻量级进程（light weight process，LWP），而资源所有权的部分通常称为进程。

多线程(multithreading)：操作系统在单个进程内支持多个并发路径的能力。

每个进程中只有一个线程在执行（没有考虑线程的概念）的方法，称作单线程方法。

一个进程中可能有多个线程，每个线程有：
- 执行状态（运行、就绪等）
- 未运行时保存的线程上下文
- 执行栈
- 用于局部变量的静态存储空间
- 与进程内其他线程共享的内存和资源访问

### 线程的优点
- 创建线程的时间少于创建进程时间
- 终止线程比终止进程所花时间少
- 同一进程内线程切换时间，少于进程切换时间
- 线程提高了不同执行程序间通信的效率

在支持线程的操作系统中，调度和分派是在线程基础上完成
- 大多数与线程相关的信息保存在线程级的数据结构中
- 挂起一个进程会挂起内部所有线程
- 终止一个进程会终止内部所有线程

### 线程主要状态
- 运行
- 就绪
- 阻塞

### 和线程变化相关的基本操作
- 派生
- 阻塞
- 解除阻塞
- 结束

### 用户级线程和内核级线程
#### 用户级线程（ULT）
所有线程管理工作由应用程序完成

内核意识不到线程的存在

优点:
- 线程切换不需要内核模式特权
- 调度策略因应用程序不同而不同
- 可以运行在任何操作系统上


缺点:
- 在典型的操作系统中, 许多系统调用都会引起进程阻塞

  因此，当用户级线程执行系统调用时，不仅阻塞当前线程，还将引起同一进程中的其他线程阻塞
- 采用ULT策略，不能利用多处理技术

#### 内核级线程（KLT）
- 线程管理由内核完成
- 应用程序没有线程管理的工作
- 如Windows

优点
- 内核可以把同一个进程内的多个线程调度到多处理器上
- 当一个线程阻塞时，内核可以调度同一进程内的其他线程
- 内核例程本身也可以是多线程的

缺点
- 把控制权从一个线程传递到相同进程内的另一个线程时，需要切换到内核模式

#### 混合方法
- 线程创建在用户空间完成
- 线程调度和同步也由应用程序完成
- 一个应用程序中的多个线程被映射到一些（小于或等于用户级线程数）内核线程上

## 单处理器调度
### 调度的类型
处理器调度的目的：满足系统目标（响应时间、吞吐量、处理器效率）的方式，把进程分配到一个或多个处理器上执行。

处理器调度分为三类:
- 长程调度
- 中程调度
  - 短程调度

#### 长程调度
- 长程调度决定了哪个程序可以进入系统中处理
- 控制系统中的并发度

在批处理系统或操作系统的批处理部分中, 新提交的作业会发送到磁盘, 并保存在一个批处理队列中. 长程调度程序运行时, 从队列中创建相应的进程.

这时会涉及两个决策
- 何时创建一个新进程的决策
- 下次允许哪个作业进入的决策

![](https://raw.githubusercontent.com/zgw0/blog/master/imgs/processTransformation22.png)

#### 中程调度
- 交换功能的一部分
- 换入决定取决于系统并发度的需求
- 在不使用虚存的系统中，换入决策还需考虑换出进程的存储需求

#### 短程调度
- 称为分派程序
- 执行最频繁
- 精确决定下次执行哪个进程
- 导致当前进程阻塞或抢占当前运行进程的事件发生时，调用短程调度程序。
  - 时钟中断
  - I/O中断
  - 系统调用
  - 信号（如信号量）

### 调度的规则
#### 与调度相关的一些概念
响应时间
- 从用户提交一个请求开始，到接收响应之间的时间间隔
- 响应时间的构成, 输入传送时间 + 处理时间 + 响应传送时间


截止时间
- 某任务必须开始执行的最迟时间，或必须完成的最迟时间。

系统吞吐量
- 在单位时间内，系统所完成的进程数。


处理器利用率
- 处理器处于忙状态的时间百分比。

周转时间（驻留时间） 
- 一个进程从提交到完成之间的时间间隔。
- 周转时间的构成：等待资源的时间+执行时间
  - 等待资源包括处理器资源

- 驻外存等待调用时间 + 驻外存等待调用时间 + 执行时间 + 阻塞时间

![](https://raw.githubusercontent.com/zgw0/blog/master/imgs/turnover_time.png)

比起周转时间, 更有用的是归一化周转时间, 它是周转时间与服务时间的比值, 表示一个进程的相对延迟情况.

短程调度的主要目标：按照优化系统某些方面的方式，来分配处理器时间

由一系列的规则来衡量调度策略

从用户与系统的角度划分
- 面向用户的规则
  - 与单个用户或进程感知到的进程行为有关，如交互系统的响应时间
  - 在所有系统中都很重要


- 面向系统的规则
  - 关注处理器的利用率（如进程的完成速度）
  - 通常在单用户系统里重要性要低一些

#### 调度规则总结
- 面向用户，与性能相关

周转时间、响应时间、 最后期限（截止时间）
- 面向用户，与性能无关

可预测性
- 面向系统，与性能相关

吞吐量、 处理器利用率
- 面向系统，与性能无关

公平性、强制优先级、平衡资源

### 调度的决策模式
#### 非抢占（非剥夺）
执行进程只有在执行完毕，或因申请I/O或请求某些操作系统服务而阻塞自己时，才释放处理机。
#### 抢占（剥夺）
- 执行进程可能被操作系统中断，并转换为就绪态。
- 抢占可能发生在
  - 新进程到达时
  - 中断发生后把一个阻塞进程置为就绪态
  - 周期性的时钟中断

调度的选择函数（selection function）
- 决定下次选择哪个就绪进程执行
- 可以基于优先级、资源需求或进程的执行特性
- 基于执行特性时的关键参数
  - w = 目前为止在系统里的等待时间
  - e = 目前为止花费的执行时间
  - s = 进程所需的总服务时间，包括e; 这个参数需要估计或者由用户提供

### 调度算法
常见的调度算法
- 先来先服务
- 时间片轮转
- 短作业优先
- 剩余时间最短优先
- 响应比高者优先
- 反馈

![](https://raw.githubusercontent.com/zgw0/blog/master/imgs/scheduling_policies.png)

下面的分析均基于这个示例

| 进程 | 到达时间 | 服务时间 |
| ---- | -------- | -------- |
| A    | 0        | 3        |
| B    | 2        | 6        |
| C    | 4        | 4        |
| D    | 6        | 5        |
| E    | 8        | 2        |

#### 先来先服务(FCFS)

- 属于非抢占调度方式
- 有利于CPU繁忙型的进程，而不利于I/O繁忙型的进程
- 不适合直接用于单处理器系统，通常与其它调度算法混合使用
- 平均周转时间长
- 对长进程有利，不利于短进程
#### 时间片轮转调度算法（RR）
算法：Round Robin

- 每个进程被分配一个时间片，周期性产生时钟中断，中断时当前进程进入就绪队列末尾，基于FCFS选择下一个作业运行
- 如果进程在时间片内阻塞或结束，则立即切换CPU


RR算法在通用的分时系统或事务处理系统中特别有效。

![](https://s2.ax1x.com/2019/06/19/VOdrgP.png)

- 属于抢占调度方式
- 常用于分时系统或事务处理系统
- 时间片的设置与系统性能、响应时间密切相关
- 时间片太短——进程切换频繁，降低CPU效率；
- 时间片太长——引起对短的交互请求的响应时间变长。
- 时间片最好略大于一次典型交互的时间
- 对CPU密集型（繁忙型）进程有利，对I/O型密集型（繁忙型）进程不利
  - CPU密集型进程可充分利用时间片
  - 而I/O密集型进程每次短时间使用CPU，之后I/O阻塞，I/O操作完成加入就绪队列后，若有CPU密集型进程占用CPU，或就绪队列里已经有CPU密集型进程，则需要长时间等待
  - CPU密集型进程不公平的使用了大部分CPU时间，导致I/O密集型进程性能下降

RR算法的改进：VRR算法

增加一个辅助队列，接收I/O阻塞完成的进程，调度优先于就绪队列，但占用的处理机时间小于就绪队列的时间片。

算法分析：VRR算法比RR算法公平。
#### 短作业优先(Shortest Job/Process First, SJF/SPF)
- 非抢占调度方式
- 短进程跳到队列头，可能导致长进程饥饿。
- 有利于短进程，减小了平均周转时间。
- 缺少剥夺机制，不适用于分时系统或事务处理环境。
进程的长短根据用户所提供的估计执行时间而定，用户估计不准时，导致该算法不一定能真正做到短作业优- 先调度。

#### 剩余时间最短优先(Shortest Remaining Time, SRT)
调度程序总是选择预期剩余时间最短的进程

当一个新进程加入就绪队列时，如果它比当前运行的进程具有更短的剩余时间，就可能抢占当前正在运行的进程。

在SJF的基础上增加了剥夺机制

##### 优点
既不像FCFS那样偏爱长进程，也不像RR算法那样会产生很多额外的中断（因时间片而产生），从而减少了开销。

周转时间方面，SRT比SJF性能要好，只要就绪，短作业可以立即被选择执行。
##### 问题
- 需要估计预期的服务时间
- 存在长进程饥饿现象
- 必须记录进程的已服务时间

#### 响应比高者优先(Highest Response Ratio Next)
当前进程执行完毕或需要阻塞时, 选择就绪队列中响应比最高的进程投入进行.

- 实质上是一种动态优先权调度算法
- 这种算法说明了进程的年龄，具有吸引力
- 是FCFS和SJF的结合，既照顾了短进程，又考虑了作业到达的先后次序，不会使长进程长期得不到服务
- 利用该算法时，每次调度之前，都须先做响应比的计算，会增加系统开销，且难以准确计算。

#### 反馈(Feedback, FB)
- 短进程优先、剩余时间最短者优先、响应比高者优先调度算法
- 采用了“奖励短进程”的思想。虽然性能较好，但均基于进程的预期执行时间——未来。
- 采用了“惩罚运行时间较久的进程” 的思想。
- 关注的是“已经执行”的时间
- 根据进程执行历史，调度基于抢占原则（按时间片）
- 采用动态优先级机制，可以获得较好的性能。

基于时间片轮转的反馈调度算法
1. 设置多个就绪队列，每个队列赋予不同优先级。
   - 第一队列优先级最高，依次递减；
   - 各个队列中进程执行的时间片不相同，优先级越高的队列，时间片越小。
1. 新进程进入时，首先放入第一个队列尾，按FCFS原则排队。
1. 如果进程在当前队列规定的时间片内完成则退出，一般而言，从队列i中调度的进程允许执行2i的时间，然后才被抢占，降级到下一个优先级队列（如果没有被抢占，则当前进程不降级）。
1. 到达最低优先级队列后，不再降级。
1. 仅当第一队列空闲时，才调度第二队列中的进程，依次类推

评价：多级反馈队列调度算法具有较好的性能，能较好地满足各种类型用户的需要。
- 有利于终端型作业用户

    常为短作业，能在第一队列所规定的时间片内完
- 对短作业用户有利

    能在前几个队列所规定的时间片内完成。
- 长进程

	将依次在第1，2,…，n个队列中运行，随着优先级下降，分配的时间片增加，减少了抢占次数。

### 实时系统和实时调度
系统能够及时（即时）响应外部事件的请求，在规定的时间内完成对该事件的处理，并控制所有实时任务协调一致地运行。

对于实时系统而言，系统的正确性不仅取决于计算的结果，而且还依赖于产生结果的时间。

实时任务

具有及时性要求的、常常被重复执行的特定进程，在实时系统中习惯称为任务。

截止时间

- 开始截止时间：任务在某时间以前，必须开始执行。
- 完成截止时间： 任务在某时间以前必须完成。

#### 实时操作系统特点
- 可确定性(determinism):任务按照固定的、预先确定的时间或时间间隔进行
- 可响应性(responsiveness):关注系统在知道中断后为中断提供服务的的时间
- 用户控制(user control):用户能够区分软、硬实时任务，并控制任务优先级
- 可靠性(reliability)：实时响应和控制事件，保障性能
- 失效弱化(fail-soft operation)：系统具有稳定性，当不能满足所有任务的实时性时，首先满足重要的、优先级高的任务的期限，减少系统故障

#### 实时进程的调度方式（基于抢占的实施方式分类）

- 基于时间片的轮转抢占(剥夺)式调度
- 基于优先级的非抢占式调度
- 基于优先级的抢占点抢占调度
- 立即抢占式调度

#### 实时调度的方法分类
- 静态表驱动调度法
- 静态优先级抢占调度法
- 基于动态规划的调度法
- 动态尽力调度法

#### 期限调度
针对具有完成限期的周期性实时任务
- 此类任务是周期性的，可预测的
- 采用最早截止时间优先调度算法
- Earliest Deadline First，EDF
- 根据任务的截止时间来确定任务的优先级

## 同步
多道程序设计为什么需要同步？
- 进程是计算机中的独立个体，且具有异步性、并发性
- 资源是计算机中的稀缺个体，需共享，如CPU、内存、I/O设备
- 进程之间可能需要协作完成任务,如C/S程序

相关术语

- 原子操作：

    由一个或多个指令序列实现的动作或函数，对外不可见，一组指令要么都执行，要么都不执行。

- 互斥

    当一个进程在临界区访问共享资源时，其他进程不能进入该临界区访问共享资源的情形

- 临界资源

    不可同时访问，必须互斥访问的资源，如打印机
- 临界区

    访问临界资源的代码，任意时刻只能由一个进程在这段代码中运行。

- 忙等现象 

    当一个进程等待进入临界区时，它会继续消耗处理器的时间

- 活锁

    两个或两个以上的进程为响应其他进程而持续改变自己状态但是不做有用工作的情形

- 死锁

    两个或两个以上的进程因等待其他进程做完某些事而不能继续执行的情形。

- 竞争条件

    多个进程或线程读写共享的数据时，结果取决于多个进程的指令执行顺序。

- 饥饿

    一个具备执行条件的进程，被调度程序无限期的忽视而不能调度的情形。

### 进程的交互方式
#### 进程间的资源竞争
- 进程间不知道彼此的存在
- 进程竞争使用同一资源时，它们之间会发生冲突
- 这类资源如：I/O设备、存储器、处理器、时钟

进程竞争资源时，并发控制面临三个问题
- 互斥
- 死锁
- 饥饿

#### 进程间通过共享合作
- 多个进程可能共享一个变量、共享文件或数据库
- 一个进程的结果可能取决于从另一个进程获得的信息
- 进程知道其他进程也可能共享同一个数据，因此必须合作

进程通过共享合作时，并发控制面临四个问题

- 互斥
- 死锁
- 饥饿
- 数据一致性

#### 进程间通过通信合作
- 进程间通过通信完成同步和协调彼此活动
- 一个进程的结果可能取决于从另一个进程获得的信息
- 通信可由各种类型的消息组成，发送或接收消息的原语由操作系统或程序设计语言提供
- 不涉及对共享资源的访问


进程通过通信合作时，并发控制面临两个问题

- 死锁
- 饥饿

### 互斥
互斥的要求
- 必须强制实施互斥
- 一个在非临界区停止的进程不能干涉其他进程
- 不会死锁和饥饿
- 没有程序在临界区中时, 任何需要进入临界区的进程必须能够立即进入
- 对相关进程的执行速度和处理器的数量没有任何要求和限制
- 一个进程驻留在临界区的时间必须是有限的

#### 互斥: 硬件的支持
- 中断禁用
- 专用机器指令
  
  机器指令方法的特点:
  - 适用于单处理器或共享内存的多处理器上的任意数量的进程
  - 简单且易于证明
  - 可用于支持多个临界区, 每个临界区可以用它自己的变量定义
  - 使用了忙等待
  - 可能饥饿
  - 可能死锁

#### 互斥: 软件解决方法
Dekker 算法和 Peterson 算法

软件方法的评价
- 软件方法始终不能解决“忙等”现象，降低系统效率。
- 采用软件方法实现进程互斥使用临界资源比较困难
- 通常能实现两个进程的互斥，很难控制多个进程的互斥。
- 算法设计需要非常小心，否则可能出现死锁，或互斥失败等严重问题。

### 信号量
信号量实现进程互斥与同步的基本原理

- 两个或多个进程可以通过传递信号进行合作
  - 迫使进程在某个位置暂时停止执行（阻塞）
  - 直到它收到一个可以“向前推进”的信号（被唤醒）。
- 将实现信号灯作用的变量称为信号量

一个信号量可以初始化为非负数
- semWait （Wait或P）操作使信号量的值减少1，若值变为负数，则阻塞执行semWait( Wait或P)操作的进程
- semSignal（Signal或V）操作使信号量的值增加1，若值小于等于零，则被semWait(Wait或P)阻塞的进程解除阻塞

信号量分类
- 二元信号量：信号量的值只能是0或1
- 计数信号量：非二元信号量/一般信号量

信号量原语的定义
```c
struct semaphore {
    int count;
    queueType queue;
}
void semWait(semaphore s)
{
    s.count--;
    if(s.count < 0) {
        // 把当前进程插入阻塞队列
        // 阻塞当前进程
    }
}
void semSignal(semaphore s)
{
    s.count++;
    if(s.count <= 0) {
        // 把当前进程从阻塞队列移除
        // 把当前进程插入就绪队列
    }
}
```

二元信号量原语定义
```c
struct semaphore {
    int value;
    queueType queue;
}
void semWait(semaphore s)
{
    if(s.value == 1) {
         s.value = 0;
    } else {
        // 把当前进程插入 s.queue
        // 阻塞当前进程
    }
}
void semSignal(semaphore s)
{
    if(s.queue is empty) {
        s.value = 1;
    } else {
        // 把当前进程从 s.queue 移除
        // 把当前进程插入就绪队列
    }
}
```

强信号量: 被阻塞时间最长的进程最先从队列释放

弱信号量: 无规定

### 经典同步问题

#### 生产者消费者

![](https://s2.ax1x.com/2019/06/19/VXBTO0.png)

![](https://s2.ax1x.com/2019/06/19/VXDe1A.png)

#### 读者和写者问题
问题描述
- 多个进程访问一个共享数据区

    其中若干读进程只能读数据，若干写进程只能写数据.
	为数据库、文件、内存区及一组寄存器等的数据访问问题建立了一个通用模型。。
- 示例——联网售票系统、12306

    在该系统中，数据的查询和更新非常频繁，不可避免会出现多个进程试图查询或修改（读/写）其中某一条数据的情形。

读者/写者进程满足的条件

- 允许多个读者进程可以同时读数据；
- 不允许多个写者进程同时写数据，即只能互斥写数据；
- 若有写者进程正在写数据，则不允许读者进程读数据——互斥读写

判断一个问题是生产者／消费者问题，还是读者／写者问题
1. 生产者／消费者问题：数据消费后就没有了；

    读者／写者问题：数据可多次读。
2. 生产者／消费者问题：消费者彼此互斥；

    读者／写者问题：读者可以同时读。

##### 读者优先
- 一旦有读者正在读数据，则允许随后的读者进入读数据。
- 只有当全部读者退出，才允许写者进入写数据。
- 导致写者饥饿

读者优先的变量设置
- wsem：互斥信号量，用于Writers间互斥，Writers和Readers互斥
- readcount：统计同时读数据的Readers个数
- mutex：对变量readcount互斥算术操作

```c
int readcount=0；
semaphore mutex = 1, wsem=1;

void reader() { 
 while (1) {
  P(mutex);
   readcount++;
   if (readcount==1) P(wsem); 
  V(mutex);
  READ;
  P(mutex);
   readcount--;
   if (readcount==0) V(wsem);
  V(mutex);
  }
}

void writer() {
 while (1) {
   P(wsem);
    WRITE;
   V(wsem);
 }
}
```

##### 公平优先
写过程中，若其它读者、写者到来，则按到达顺序处理。

公平优先的变量设置
- wsem：互斥信号量，用于Writers间互斥，Reader互斥Writers
- readcount：统计同时读数据的Readers个数
- mrc：对变量readcount互斥算术操作
- wrsem：互斥信号量，确定Writer 、Reader请求顺序

```c
int readcount=0, semaphore mrc=l, wrsem=1, wsem=l;

void reader() {
  while (true) {
    P(wrsem);
    P(mrc);
      readercount++;
      if (readercount == 1)
        P(wsem);
    V(mrc);
    V(wrsem);
      READ;
    P(mrc);
      readercount--;
      if (readercount == 0)
        V(wsem);
    V(mrc);
  }
}

void writer() {
  while (true) {
    P(wrsem);
    P(wsem);
      WRITE;
    V(wsem);
    V(wrsem);
  }
}
```
##### 写者优先
- 当至少有一个写者准备写数据时，则不再允许新的读者进入读数据。
- 保证当有一个写进程声明想写时，不允许新的读进程访问数据区；
- 解决了写者饥饿问题，但降低了并发程度，系统的并发性能较差。

写者优先的变量设置
- rsem：互斥信号量，当至少有一个写者申请写数据时互斥新的读者进入读数据。
  
  第一个写者受rsem影响，一旦有第一个写者，后续写者不受rsem其影响。但是读者需要在rsem上排队。
- writecount：用于控制rsem信号量
- mwc：对变量 writecount 互斥算术操作

```c
// v1
int readcount = 0, writecount = 0;
semaphore mrc=l, mwc= 1, wsem=1, rsem=l;

void reader( ) {
   while (1) {
      P(rsem);
       P(mrc);
        readcount++;
        if (readcount ==1) P(wsem);
       V(mrc);
      V(rsem)；
     READ;
     P(mrc);
      readcount--;
      if (readcount ==0) V(wsem);
     V(mrc);
   }
}

void writer( ) {
  while (1) {
    P(mwc);
     writecount++;
     if (writecount ==1) P(rsem);
    V(mwc);
    P(wsem);
     WRITE;
    V(wsem);
    P(mwc);
     writecount--;
     if (writecount==0) V(rsem);
    V(mwc);
  }
}
```

```c
// v2
int readcount=0,writecount=0; semaphore mrc=l, mwc= 1,z=1,wsem=1,rsem=l;

void reader( ) {
   while (1) {
     P(z);
      P(rsem);
       P(mrc);
        readcount++;
        if (readcount ==1) P(wsem);
       V(mrc);
      V(rsem)；
     V(z);
     READ;
     P(mrc);
      readcount--;
      if (readcount ==0) V(wsem);
     V(mrc);
   }
}

void writer( ) {
  while (1) {
    P(mwc);
     writecount++;
     if (writecount ==1) P(rsem);
    V(mwc);
    P(wsem);
     WRITE;
    V(wsem);
    P(mwc);
     writecount--;
     if (writecount==0) V(rsem);
    V(mwc);
  }
}

```


z信号量的作用：
- 在rsem上不允许建造读进程的长队列，否则写进程将不能跳过这个队列.
- 允许一个读进程在rsem上排队,其他读进程在信号量z上排队
- P(z)和P(rsem)能否互换位置？

### 管程
#### 管程的概念(Monitor)
- 一个管程定义了一个共享数据结构和能为并发进程所执行（在该数据结构上）的一组操作（过程），这组操作能同步进程和改变管程中的数据。（C. A. R. Hoare & Per Brinch Hansen）
- 共享数据结构是对系统中共享资源的抽象
- 对该共享数据结构的操作则定义为一组过程，通过调用这些过程实现对共享资源的申请、释放和其它操作。


> 管程 (英语：Monitors，也称为监视器) 是一种程序结构，结构内的多个子程序（对象或模块）形成的多个工作线程互斥访问共享资源。这些共享资源一般是硬件设备或一群变量。管程实现了在一个时间点，最多只有一个线程在执行管程的某个子程序。与那些通过修改数据结构实现互斥访问的并发程序设计相比，管程实现很大程度上简化了程序设计。

> 管程提供了一种机制，线程可以临时放弃互斥访问，等待某些条件得到满足后，重新获得执行权恢复它的互斥访问。

> 维基百科
#### 管程的引入
- 信号量可以高效的实现进程间互斥与同步,但是:
- 信号量的P、V操作可能分散在整个程序中，使用难度高。
- 管程是一个程序设计语言结构，采用了集中式的进程同步方法，提供了与信号量同样的功能，但更易于控制。
- 很多程序设计语言都支持管程，如Pascal、Java等。

#### 管程的组成
局部数据 + 过程 + 初始化序列

一个管程包含:

- 多个彼此可以交互并共享资源的线程
- 多个与资源使用有关的变量
- 一个互斥锁
- 一个用来避免竞态条件的不变量
#### 特点
- 局部数据变量只能被管程的过程访问, 其余的外部过程都不能访问
- 一个进程通过调用管程的一个过程进入管程
- 在任何时候只能有一个进程正在管程执行, 调用管程的其他任何进程都被阻塞, 以等待管程可用

#### 用管程实现进程同步
- 管程通过使用条件变量提供对进程同步的支持。
- 条件变量包含在管程中，只能在管程中访问。
- 操作条件变量的两个函数

```
cwait(c) // 调用进程的执行在条件c上阻塞，管程可供其它进程使用。
csignal(c) // 恢复在条件c上阻塞的一个进程，若不存在阻塞进程，则什么都不做。
```

#### 管程的结构

![](https://s2.ax1x.com/2019/06/21/VzAktg.png)

### 消息传递
进程交互时需要满足两个基本要求

- 同步, 可以保证互斥
- 通信, 交换信息

消息传递提供了上面两个功能

- 两条通信原语      

  - Send(destination,message)
  - Receive(source,message)
- 进程以消息的形式给指定的进程（目标）发送信息
- 进程通过接收原语receive接收消息，接收原语中指明源进程和消息

#### 消息传递的三种同步方式
- 阻塞发送，阻塞接收
- 不阻塞发送，阻塞接收
- 不阻塞发送，不阻塞接收

#### send和receive原语确定目标和原进程的方式有两类
直接寻址和间接寻址

#### 使用消息传递实现互斥
- 多个并发执行的发送进程和接收进程共享一个邮箱box，且box的初始状态为仅包含一条“空消息”（好比进入临界区的令牌）；
- 采用“不阻塞发送，阻塞接收”方式传递消息；
- 若邮箱中存在一条消息，则允许一个进程进入临界区。
- 若邮箱为空，则表明有一个进程位于临界区，其它试图进入临界区的进程必须阻塞。
- 只要保证邮箱中最多只有一条消息，就能保证只允许一个进程进入临界区，从而实现进程互斥使用临界资源。

## 死锁
- 定义：一组相互竞争系统资源或进行通信的进程间的永久阻塞。
- 当一组进程中的每个进程都在等待某事件，而只有同组进程中阻塞的其他进程能够促发该事件时，死锁发生。
- 永久性的
- 无有效的解决方案

### 资源的分类

- 可重用资源

    一次仅供一个进程安全使用且不因使用而耗尽的资源

    如处理器、I/O通道、内存和外存、设备，以及诸如文件、数据库和信号量之类的数据结构之类的

- 可消耗资源

    可消耗资源是指可被创建（生产）和销毁（消耗）的资源。

    如中断、信号、消息和I/O缓冲中信息

### 死锁的条件
必要条件
- 互斥, 一次只有一个进程可以使用一个资源
- 占用且等待, 当进程等待其他资源时，继续占有已经分配的资源
- 不可抢占, 不能强行抢占进程已经占有的资源

充分条件
- 循环等待, 存在一个闭合的进程链，每个进程至少占有此链中下一个进程所需的一个资源

### 死锁的解决
#### 预防

防止死锁产生条件的发生

- 间接方法：防止三个必要条件中的任意一个条件发生
- 直接方法：防止循环等待的发生
#### 避免

允许三个必要条件，根据当前资源分配状态来做出资源分配决策，保证不产生死锁

- 若一个进程的请求会导致死锁, 则不启动该进程
- 资源分配拒绝, 若一个进程增加的资源请求会导致死锁, 则不允许这一资源分配

系统的状态反映出当前给进程分配资源的情况

安全状态指至少有一个资源分配序列（Px,Py,…Pz，安全序列）不会导致死锁，所有进程Px,Py,…Pz能够运行结束

不安全状态: 不存在安全序列
    
避免死锁的实质在于如何避免系统进入不安全状态

死锁避免的优点
- 无须死锁预防中的抢占和回滚进程（释放最初占有的资源）
- 比起死锁预防，限制少

死锁避免的限制
- 必须事先声明每个进程请求的最大资源
- 进程必须是独立的, 他们之间没有同步的要求
- 分配资源的数量必须是固定的
- 占有资源时进程不能退出
#### 检测与解除

不限制资源访问或约束进程行为，而是检测死锁的存在并尝试解除

- 对死锁的检测可以频繁的发生在每次资源请求时；
- 也可以少检测，如定时检测，或系统资源利用率下降时检测，具体取决于死锁发生的可能性

死锁检测算法步骤
1. 标记 Allocation 矩阵中一行全为零的进程；
2. 初始化一个临时向量W，令W等于Available向量；
3. 查找下标i, 进程i当前未标记且满足Q(Qij表示进程i请求j类资源的数量）的第i行小于等于W, 即对所有的1 <= k <= m, Q<sub>ik</sub> <= W<sub>k</sub>, 若找不到这样的行，终止算法；
4. 若找到这样的行，标记进程i，并把 Allcation 矩阵中的相应行加到 W 中，即对所有1 <= k <= m, 令W<sub>k</sub> = W<sub>k</sub> + A<sub>ik</sub>。返回3


当且仅当最终有未标记进程时，才存在死锁，未标记的进程都是死锁的。


从资源分配图化简的角度解决问题

资源分配图的化简
- 在资源分配图中，找出其全部请求都能满足的进程节点Pi，消去Pi所有的请求边和分配边，使之成为孤立的结点。
- 重复步骤①，直至无法化简为止。

解除：检测到死锁后，按照某种可能的策略来解除
1. 撤消进程

   - 撤消所有死锁进程
   - 连续撤消死锁进程直到不再存在死锁

2. 回退

   - 把进程回退到前面定义的某些检查点，并重新启动所有进程

3. 抢占

   - 连续抢占资源直到不再存在死锁

取消哪些进程、抢占哪些进程的资源？选择原则：

目前为止消耗处理器时间少，或输出少，或分配资源少，或剩余时间长，或优先级最低的进程

#### 哲学家就餐问题
##### 为餐叉编号；
就餐前，先取用编号较低的餐叉，再取用编号较高的餐叉；

就餐毕，先放下编号较高的餐叉，再放下编号较低的餐叉。
```c
semaphore fork[5] = {1, 1, 1, 1, 1};
void main()
{
   cobegin {philosopher(0); philosopher(1); philosopher(2); philosopher(3); philosopher(4);}coend;
}
void philosopher(int i)
{
   while(true) {
      think();  //思考
      if (i  !=  4) {
           wait(fork[i]); wait(fork[(i+1)%5]);} //先左后右
       else {
           wait(fork[(i+1)%5]); wait(fork[i]);} //先右后左
       eat(); 
       if (i  !=  4) {
           signal(fork[(i+1)%5]); signal(fork[i]);} //先右后左
       else {
           signal(fork[i]); signal(fork[(i+1)%5]);} //先左后右
    }
}
```

##### 为哲学家编号；
奇数号的哲学家必须首先拿左边的餐叉；

偶数号的哲学家必须首先拿右边的餐叉。

```c
semaphore fork[5] = {1, 1, 1, 1, 1};
void main()
{
   cobegin {philosopher(0); philosopher(1); philosopher(2); philosopher(3); philosopher(4);}coend;
}
void philosopher(int i)
{
   while(true) {
     think();  //思考
     if (i % 2 != 0) {
         wait(fork[i]); wait(fork[(i+1)%5]);} //先左后右
     else {
         wait(fork[(i+1)%5]); wait(fork[i]);}
     eat(); 
     signal(fork[(i+1)%5]);                         //先右后左
     signal(fork[i]);   
}
}
```

##### 服务生方法
引入一个餐厅服务生，哲学家必须经过他的允许才能拿起餐叉；

最多允许4个哲学家同时进食。

```c
semaphore fork[5] = {1, 1, 1, 1, 1}, room = 4;
void main()
 {
   cobegin {philosopher(0); philosopher(1); philosopher(2); philosopher(3); philosopher(4);}coend;
}
void philosopher(int i)
{
   while(true) {
      think;                                        //思考
      wait(room);                             //占据就餐位置
      wait(fork[i]);                           //拿起左边的叉子
      wait(fork[(i+1)%5]);               //拿起右边的叉子
      signal(fork[i]);                         //放回左边的叉子
      signal(fork[(i+1)%5]);           //放回右边的叉子
      signal(room);                          //释放就餐位置
   }
}
```

### UNIX 并发机制
- 管道
- 消息
- 共享内存
- 信号量
- 信号


# 内存管理

## 基本内存管理

### 程序的加载和连接

高级语言的源代码转化为进程的三个步骤
- 编译, 由 compiler 把用户代码编译成若干个目标模块
- 链接, 有 linker 将编译后形成的一组目标模块及他们需要的库函数链接在一起, 形成一个完整的装入模块
  
  - 静态链接
  - 装入时链接
  - 运行时链接

- 加载(装入), 由 loader 将装入模块装入内存

  - 绝对加载
  - 可重定位加载
  - 动态运行时加载

### 内存管理的需求
#### 重定位
- 程序员事先并不知道在某个程序执行期间会有其他哪些程序驻留在内存中
- 需要把活动进程换入或换出内存，进而使处理器的利用率最大化
- 进程下次换入时要放置在与换出前相同的区域存在诸多困难
- 需要将进程重定位（relocation）到内存的不同区域

#### 保护
- 进程以外的其他进程中的程序不能未经授权地访问（进行读操作或写操作）该进程的内存单元
- 程序在内存中的位置不可预测
- 需要既要支持重定位也支持保存的机制

#### 共享
- 多个进程正在执行同一程序时，允许每个进程访问该程序的同一个副本，要比让每个进程有自己独立的副本更有利。
- 需要既支持重定位也支持共享的机制

#### 逻辑组织
- 内存被组织成线性（或一维）地址空间
- 分段可以满足该需求

好处
- 可以独立编写和编译模块
- 可以为不同的模块提供不同的保护级别（只读、只执行）
- 模块可以被多个进程共享，与用户看待问题的方式一致

#### 物理组织

不应让程序员负责管理内存
- 供程序和数据使用的内存可能不足
- 程序员不知道可用空间的大小和位置
- 覆盖（overlaying）允许不同的模块占用相同的存储空间，但编程耗时

### 内存分区

内存管理的主要操作是处理器把程序装入内存中执行

#### 固定分区
基本原理
- 操作系统占据内存中某些固定部分，用户进程使用其余部分
- 将用户空间的内存区域进行划分，形成若干个边界固定的区域
- 每个分区装入一个进程

#### 动态分区
- 动态分区方法在内存中产生越来越多的碎片
- 内存利用率下降

紧凑(压缩)Compaction

- 解决外部碎片问题的技术
- 操作系统移动进程，使进程占用的空间连续
- 所有空闲空间连成一片
- 紧凑费时，浪费处理器时间

#### 伙伴系统
伙伴系统的特点
- 较为合理的折中方案，一定程度上克服了固定分区和动态分区的缺陷
- 是并行程序分配和释放的一种有效方案
- UNIX内核存储分配中使用了一种经过改进的伙伴系统

#### 重定位分区

![](https://s2.ax1x.com/2019/06/21/ZShqJJ.png)

#### 对换
把内存中暂不能运行的进程或者暂不使用的程序和数据换出到外存上，以腾出足够的内存空间，把已具备运行条件的进程或进程所需要的程序和数据换入内存。

### 离散分配
一个进程分配的内存由多个离散的空间组成
#### 分页
- 将内存划分成大小固定、相等的块，且块相对较小
- 进程也划分成同样大小的块

页: 进程中的块

页框: 内存中的块

页表
- 操作系统为每个进程维护一个页表
- 页表给出了该进程的每页所对应页框的位置
- 处理器必须知道如何访问当前进程的页表
- 逻辑地址到物理地址的转换由处理器硬件完成

分页的优点
- 存在页内碎片，但碎片相对较小，内存利用率较高
- 实现了离散分配
- 无外部碎片

分页的缺点
- 需要专门的硬件支持，尤其是快表
- 不支持动态链接，不易实现共享

#### 分段

- 一个程序可以划分成几个段（segments）

    - 段长度可以不等 
    - 每个段都从0开始编址，并占用一段连续的地址空间
    - 有最大段长限制
- 逻辑地址两部分组成

    - 段号 
    - 段内偏移量 
- 分段类似动态分区

    - 分段使一个程序可以占据多个分区，且不必连续
- 消除了内部碎片

分段的特点
- 分页对用户透明，分段对用户可见
- 给程序员提供了组织程序和数据更方便的手段
- 程序员或编译器将程序和数据划分到不同的段
- 为实现模块化程序设计，程序和数据可能会进一步被划分成多个段
- 不便：程序员或编译器需要清楚最大段长的限制

分段的优点
- 便于程序模块化设计
- 便于动态链接
- 便于保护和共享
- 无内部碎片
分段的缺点
- 地址转换需要硬件的支持——段表寄存器
- 分段的最大尺寸受到主存可用空间的限制
- 有外部碎片

分页和分段的比较
- 页是信息的物理单位，分页的目的是实现离散分配，减少内存的外部碎片，提高内存的利用率。或者说，分页仅仅是由于系统管理的需要而不是用户的需要。段则是信息的逻辑单位，它含有一组意义相对完整的信息。分段的目的是为了能更好地满足用户的需要。
- 页的大小固定且由系统决定，由系统把逻辑地址划分为页号和页内地址两部分，是由机器硬件实现的，因而在系统中只能有一种大小的页面；而段的长度却不固定，决定于用户所编写的程序，通常由编译程序在对源程序进行编译时，根据信息的性质来划分。
- 分页的作业地址空间是一维的，即单一的线性地址空间，程序员只需利用一个记忆符，即可表示一个地址；而分段的作业地址空间则是二维的，程序员在标识一个地址时，既需给出段名，又需给出段内地址。
- 分页存储管理系统不易实现“共享”和“运行时动态链接”，而分段系统易于实现实现。

#### 段页式

- 页式存储管理的主要优点
         
    内存利用率高
- 段式存储管理的主要优点
  
    方便用户、易于共享、易于保护、可动态链接
- 段页式存储管理的基本思想

    采用分段方法组织用户程序，采用分页方法分配和管理内存。即用户程序可以用模块化思想进行设计，一个用户程序由若干段构成。系统将内存划分成固定大小的页框，并将程序的每一段分割成若干页后装入内存执行时。

段页式的优点
- 离散存储
- 内存利用率高
- 便于保护和共享，支持动态链接
- 无外部碎片
段页式的缺点
- 地址转换复杂
- 有内部碎片

## 虚拟内存管理

要使虚存比较实用且有效
- 分页或分段的硬件支持
- 操作系统必须有管理页或段在内存和辅存之间移动的软件

进程的执行过程：
- 操作系统仅读取包含程序开始处的一个或几个块进入内存
- 任意时刻，进程驻留在内存中的部分——驻留集
- 访问一个不在内存中的逻辑地址时（称为内存失效），产生一个中断
- 操作系统把被中断的进程置为阻塞状态
- 操作系统把该进程中包含引发内存失效的部分读入内存
  - 操作系统产生一个磁盘I/O读请求
  - 在执行磁盘 I/O期间，操作系统调度另外一个进程运行
  - 磁盘I/O完成后产生中断，操作系统将相应的进程置于就绪状态

提高系统资源利用率的方法
- 内存中保留多个进程

每个进程仅装入了部分块
任何时刻内存中的进程至少有一个处于就绪状态
提高了处理器的利用率
- 进程可以比内存的全部空间还大

基于分页和分段的技术，操作系统和硬件只加载程序的一部分
程序员面对的是一个巨大内存，大小与磁盘存储器相关

进程只有部分块在内存，这样可在内存中保留更多进程

操作系统必须“聪明”的管理这个方案

当内存空间几乎被进程块占据时，每读取一块，必须把另一块换出，如果出现抖动

抖动：将要用到的块被换出，系统又得很快将它取回，导致页面被频繁地换入换出，缺页率急剧增加

### 局部性原理
存储器的访问呈簇(cluster)性，簇在很长一段时间内，使用的簇会发生变化，但在很短的时间内，处理器基本上只与固定的簇打交道。

描述了进程中程序和数据引用的集簇倾向

在很短的时间内仅需要进程的一部分块

对将来可能会访问的块进行猜测，以避免抖动

局部性原理表明虚存方案是可行的

### 多级页表
庞大页表的离散存储解决方案——多级页表

两级页表
- 将页表进行分页，典型情况下，每页大小最大限制与进程分页大小一致，如pentium处理器
- 建立页目录，每项指向一页页表
- 如果页目录长度为X，一个页表的包含的页表项数为Y，则一个进程可以有XY页。

### 倒置页表（反置页表、倒排页表）
- 虚拟地址的页号部分使用一个简单的散列函数映射到散列表中
  - 哈希值指向倒排页表
- 无论有多少进程、支持多少虚拟页，页表都只需要实存中的一个固定部分
- 页表结构称为“倒置”的原因是，它使用页框号而非虚拟页号来索引页表项

![](https://s2.ax1x.com/2019/06/21/ZS7giT.png)

### 转换检测缓冲区TLB( translation lookaside buffer，快表)

每次虚存访问都可能会引起两次物理地址访问
- 一次取相应的页表项
- 另一次取需要的数据

为了克服这个问题，大多数虚拟内存方案都为页表项使用了一个特殊的高速缓存，称为转换检测缓冲区TLB（快表、联想存储器）
- TLB包含最近用过的页表项

具有快表的地址转换流程
- 给定一个虚拟地址，处理器首先检查TLB
- 若命中：即页表项在TLB中，检索页框号形成物理地址
- 若未命中：即页表项不在TLB中，检索进程页表，查找相应页表项
  - 若“存在位”已置位，页位于内存，用页框号+偏移量形成物理地址，同时更新快表
  - 若“存在位”未置位，页不在内存，产生缺页 (page fault)中断，装入所需页，更新页表

### 页尺寸
- 页越小，内部碎片的总量越少
- 页越小，每个进程需要的页的数量越多
- 页数量越多，进程的页表越大
- 对于多道程序设计环境中的大程序，这意味着活动进程有一部分页表在虚存而非内存，则一次内存访问可能产生两次缺页中断
  - 一次读取所需页表
  - 一次读取进程页
- 基于大多数辅存设备的物理特性，希望页尺寸比较大，从而实现更有效的数据传输

### 操作系统软件

#### 内存管理设计的三个基本选择:
- 是否使用虚拟技术
- 使用分页还是分段，或二者同用
- 为各种存储管理特征采用的算法

#### 读取策略

##### 请求调页（Demand Paging）
- 仅在引用页面时，才把相应的页面调入内存
- 进程首次启动时，会发生很多缺页中断 
- 局部性原则表明，大多数将来访问的页面都是最近读取的页面，一段时间后，缺页中断会降低到很低的水平。

##### 预调页（Prepaging）
- 额外读取所缺页面以外的页面
- 考虑大多数辅助储设备的特性：寻道、旋转延迟等
- 若进程的页面连续存储在辅存中，则一次读取多个页面会更有效
- 如果额外读取的页面未使用，则低效

#### 放置策略
- 确定进程驻留在内存中的位置
- 分段系统中的重要设计内容，如首次匹配、循环匹配等
- 分页或段内分页是无关紧要的，因为硬件以相同的效率执行地址转换功能
- 对于非一致存储访问（NonUniform Memeory Access, NUMA ）多处理器，需要自动放置策略

#### 置换策略

页面置换涉及的问题
- 给每个活动进行分配多少个页框
- 置换范围，即计划置换的页集局限于产生缺页的进程本身，还是内存内的所有进程
- 具体淘汰哪个页面用以置换

##### 页框锁定
- 当页框被锁定时，当前存储在该页框中的页面不能被置换
- 操作系统内核和重要的数据结构保存在锁定的页框中
- I/O缓冲区和时间要求严格的区域可能保存在锁定的页框中
- 通过将锁定位与每个页框相关联来实现锁定

##### 基本算法
- 最优（OPT）
- 最近最少使用（LRU）
- 先进先出（FIFO）

    Belady异常现象——先进先出算法的特有现象
    - 分配的页框数越多，缺页中断次数越少?   

        一个进程的页地址流为：1 2 3 4 1 2 5 1 2 3 4 5
        
        页地址流中的页面数为 12，进程的页面数为5
    - Belady异常现象
    
        随着分配的页框数增加，缺页中断次数有时反而增加
    - 例子   
        一个进程的页地址流为：1 2 3 4 1 2 5 1 2 3 4 5
        
        页框数为 3 时，缺页中断次数为 9
        
        页框数为 4 时，缺页中断次数为 10

- 时钟（CLOCK）

    已有该页地址, 指针不移动, 无该页地址, 填入后指针指向下一位
    
    改进型时钟置换算法实现
    1. 选择最佳淘汰页面（U=0，M=0）
    2. 如果①失败，寻找第2类页面（U=0，M=1 ），并把所扫描过的页面的访问位U置0 。
    3. 如果②失败，回到步骤①。

   改进型时钟置换算法实现简单，性能比较理想，被广泛采用。

##### 页缓冲
置换策略和高速缓存大小
- 对于较大的高速缓存，替换页会对性能产生影响
- 如果选择替换的页框在高速缓存中，则该高速缓存块及所装载的页面将失效
- 在使用页缓冲的系统中，可以使用页缓冲区中的页放置策略来提高高速缓存性能
- 大多数操作系统通过从页缓冲区中选择任意页框来放置需置换的页

#### 驻留集管理
##### 驻留集大小
固定 

在主存储器中为进程提供固定数量的帧以在其中执行

发生缺页时，必须替换该进程的其中一个页面


可变

允许分配给进程的页面帧数在进程的生命周期内变化

##### 置换范围
两种类型策略的实施都是在没有空闲页框时由缺页中断激活。

全局

在整个内存中选择置换对象，只要不是锁定的页，都可以作为候选页

局部

仅在产生缺页中断的进程的驻留页中选择置换对象

工作集

- 进程在虚拟时间t的参数为Δ的工作集W（t, Δ ），表示该进程在过去的Δ个虚拟时间单位被访问到的页集合
- 用进程访问内存的次数来衡量虚拟时间t，例如进程一系列的内存访问为r(1),r(2),…r(i)， r(i)表示
- 第i次对内存页的访问，对应的虚拟时间为1,2,…i。 Δ为给定的虚拟时间窗口大小，如2次访问。
虚拟时间窗口越大，则工作集越大

工作集策略
- 根据工作集来决定驻留集的大小
- 周期性的从驻留集中移去不在工作集中的页（近似LRU）
- 只有驻留集包含工作集时，才执行进程

平均访问时间（有效访问时间）

若缺页率为p，内存的访问时间为ma，发生缺页时的访问时间为da，则平均访问时间为(1-p)*ma+p*da

有效访问时间的构成
- 缺页服务时间
- 进程重新执行时间
- 页面调入时间——20ms
    
  寻道时间+旋转时间+数据传送时间

  由于ma很小（<10ns），因此很低的缺页率也会导致很大的平均访问时间。

#### 清除策略
清除策略用于确定何时将修改过的页写回辅存

##### 请求式清除（Demand）
只有当一页被选择用于置换时才写回辅存

发生缺页中断的进程在解除阻塞前需要等待两次页传送: 写回修改页和读入新页
##### 预约式清除（Precleaning）
将修改的多页在需要使用它们占据页框之前, 成批写回辅存

预先写回辅存的页在置换前可能被修改, 使得预约式清除的意义不大

结合页缓冲技术

只清除用于置换的页(非预先清除)

通过页缓冲，将置换的页放在已修改表和未修改表中，已修改表中的页可以成批写回辅存。
#### 加载控制
- 决定驻留在内存中的进程的数量
  - 多道程序度multiprogramming level，也称系统并发度
- 对于有效的内存管理来讲非常重要
- 内存驻留的进程太少，当所有进程阻塞时，大量时间花在交换上。
- 内存驻留的进程太多会导致抖动

L=S准则（Denning @1980）

发生缺页的平均时间L等于处理缺页故障的平均时间S，此时处理器的利用率最大
##### 多道程序度（系统并发度）
控制多道程序度
- 需挂起一个或多个驻留进程
- 选择哪些进程挂起
  - 最低优先级进程
  - 缺页中断的进程
  - 最后被激活的进程
  - 具有最小驻留集的进程
  - 最大空间的进程
  - 具有最大剩余执行时间的进程

# I/0 管理和磁盘调度
# 文件系统